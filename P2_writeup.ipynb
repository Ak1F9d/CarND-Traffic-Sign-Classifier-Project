{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: **Traffic Sign Recognition** \n",
    "\n",
    "#### The goals / steps of this project are the following:\n",
    "\n",
    "・Load the data set (see below for links to the project data set)  \n",
    "・Explore, summarize and visualize the data set  \n",
    "・Design, train and test a model architecture  \n",
    "・Use the model to make predictions on new images  \n",
    "・Analyze the softmax probabilities of the new images  \n",
    "・Summarize the results with a written report  \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rubric Points\n",
    "Here I will consider the rubric points individually and describe how I addressed each point in my implementation.  \n",
    "\n",
    "#### Dataset Exploration\n",
    "##### 1. Dataset Summary: The submission includes a basic summary of the data set.   \n",
    "   \n",
    "The code for this step is contained in the second code cell of the IPython notebook.\n",
    "\n",
    "I used the numpy library to calculate summary statistics of the traffic signs data set:\n",
    "\n",
    "    The size of training set is 34799\n",
    "    The size of test set is 12630\n",
    "    The shape of a traffic sign image is (32 x 32 x 3)\n",
    "    The number of unique classes/labels in the data set is 43\n",
    "\n",
    "##### 2. Exploratory Visualization: The submission includes an exploratory visualization on the dataset.  \n",
    "\n",
    "The code for this step is contained in the third code cell of the IPython notebook.\n",
    "\n",
    "Here is an exploratory visualization of the data set. Each rows represent each class. Each class contains 15 random images. Right numbers and bar charts show the number of images of each class.  \n",
    "\n",
    "<img src=\"visualizeimage.png\">\n",
    "\n",
    "\n",
    "#### Design and Test a Model Architecture\n",
    "##### 1. Preprocessing: The submission describes the preprocessing techniques used and why these techniques were chosen.  \n",
    "   \n",
    "The code for this step is contained in the fifth code cell of the IPython notebook.\n",
    "\n",
    "In preprocessing process, I normalized the image data because image contrast is varied by lighting conditions.\n",
    "\n",
    "To avoid the effects of background brightness, I focused on the central region of images. \n",
    "\n",
    "In addition, to avoid the effects of highlights,  I sorted the pixel values and I set the top 10% value as max value.  \n",
    "\n",
    "Here is an example of a traffic sign image after preprocessing. Image contrast fluctuation is improved.\n",
    "\n",
    "<img src=\"preprocessedimage.png\">\n",
    "\n",
    "##### 2. Model Architecture: The submission provides details of the characteristics and qualities of the architecture, including the type of model used, the number of layers, and the size of each layer. Visualizations emphasizing particular qualities of the architecture are encouraged.\n",
    "\n",
    "The code for my final model is located in the 12th cell of the ipython notebook.\n",
    "\n",
    "My final model consisted of the following layers:\n",
    "\n",
    "Layer\tDescription   \n",
    "Input\t32x32x3 RGB image   \n",
    "Convolution 3x3\t1x1 stride, valid padding, outputs 30x30x6   \n",
    "Max pooling\t2x2 stride, outputs 15x15x6   \n",
    "RELU\t \n",
    "Convolution 5x5\t1x1 stride, valid padding, outputs 11x11x16   \n",
    "Max pooling\t2x2 stride, outputs 5x5x16   \n",
    "RELU\t\n",
    "Flatten, outputs 400   \n",
    "Fully connected, outputs 120   \n",
    "RELU   \n",
    "Dropout   \n",
    "Fully connected, outputs 84   \n",
    "RELU   \n",
    "Dropout   \n",
    "Fully connected, outputs 43   \n",
    "RELU   \n",
    "Dropout   \n",
    "Softmax   \n",
    "\n",
    "##### 3. Model Training: The submission describes how the model was trained by discussing what optimizer was used, batch size, number of epochs and values for hyperparameters.\n",
    "\n",
    "The code for training the model is located in the 14th cell of the ipython notebook.\n",
    "\n",
    "To train the model, I used the following parameters:  \n",
    "Optimizer: an Adam optimizer  \n",
    "Batch size: 200  \n",
    "Epochs: 100  \n",
    "Learning rate: 0.0008  \n",
    "\n",
    "##### 4. Solution Approach: The submission describes the approach to finding a solution. Accuracy on the validation set is 0.93 or greater.\n",
    "\n",
    "The code for calculating the accuracy of the model is located in the 15th cell of the Ipython notebook.\n",
    "\n",
    "*My final model results were: *  \n",
    "training set accuracy of 0.998   \n",
    "validation set accuracy of 0.965   \n",
    "test set accuracy of 0.946   \n",
    "<img  src=\"accuracyandloss.png\"/>\n",
    "What was the first architecture that was tried and why was it chosen?\n",
    "I tried LeNet used at the end of the CNN lesson, and convert images to grayscale as preprocessing.\n",
    "\n",
    "What were some problems with the initial architecture?  \n",
    "a. Misjudgements on similar structures but different colors, e. g.  Keep left and Stop  \n",
    "b. Misjudgements on detailed structures, e. g.  Bicycles crossing and Beware of ice/snow  \n",
    "c. Overfitting: Training set accuracy was high, but validation set accuracy was low.  \n",
    "\n",
    "How was the architecture adjusted and why was it adjusted?   \n",
    "a. I used RGB color, not grayscale.   \n",
    "b. I changed the filter size of first layer to smaller one.   \n",
    "c. I used dropout and augmented images.  Augmentaion is located in the 9th cell of the notebook. I balanced the number of images per classes.  \n",
    "\n",
    "Which parameters were tuned? How were they adjusted and why?\n",
    "I tuned learning rate and set number of epochs at sufficiently large value.   \n",
    "Training converged more slowly at the smaller learning rate, but the better accuracy could be achieved. However, too small learning rate deteriorate in accuracy. I tried some values and 0.0008 was the best value.\n",
    "\n",
    "#### Test a Model on New Images\n",
    "##### 1. Acquiring New Images: The submission includes five new German Traffic signs found on the web, and the images are visualized. Discussion is made as to particular qualities of the images or traffic signs in the images that are of interest, such as whether they would be difficult for the model to classify.\n",
    "\n",
    "Here are five German traffic signs that I found on the web:\n",
    "<img  src=\"newimages.png\"/>\n",
    "The first image might be easy to classify because it's a normal stop sign.  \n",
    "The secound image might be difficult to classify because of graffiti.  \n",
    "The third image might be very difficult to classify because snow covers the most part of sign but human can classify.  \n",
    "The fourth image might be easy to classify because it's normal no entry sign.  \n",
    "The fifth image might be difficult to classify because some letters are written on the sign.   \n",
    "\n",
    "##### 2. Performance on New Images: The submission documents the performance of the model when tested on the captured images. The performance on the new images is compared to the accuracy results of the test set.\n",
    "\n",
    "The code for making predictions on my final model is located in the 19th cell of the Ipython notebook.\n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "|Image\t|Prediction|\n",
    "|-------|----------|\n",
    "|Stop Sign|\tStop sign|   \n",
    "|Stop Sign|\tStop Sign|   \n",
    "|Stop Sign|\tChildren crossing|   \n",
    "|NO Entry|\tNO Entry|  \n",
    "|NO Entry|\tNO Entry|   \n",
    "The model was able to correctly classify the all images except the third one, which gives an accuracy of 80%.    \n",
    "The third one is cover with snow and training set don't contain such images.   \n",
    "If this model were used in snow countries, the images with snow have to be contained in training set.    \n",
    "To make the model more robust, I have to preprocess the images more complicately to reduce the effect of obstacles like snow.    \n",
    "\n",
    "##### 3. Model Certainty - Softmax Probabilities: The top five softmax probabilities of the predictions on the captured images are outputted. The submission discusses how certain or uncertain the model is of its predictions.\n",
    "\n",
    "The code for making predictions on my final model is located in the 21th cell of the Ipython notebook.\n",
    "\n",
    "For the first image, the model is relatively sure that this is a stop sign (probability of 1.0), and the image does contain a stop sign. The top five soft max probabilities were\n",
    "\n",
    "Probability\tPrediction  \n",
    ".14\tStop  \n",
    ".01\tSpeed limit (30km/h)  \n",
    ".00\tSpeed limit (20km/h)  \n",
    ".38\tKeep right  \n",
    ".29\tBicycles crossing  \n",
    "\n",
    "For the second image, the model is relatively sure that this is a stop sign (probability of 0.99), and the image does contain a stop sign. The top five soft max probabilities were\n",
    "\n",
    "Probability\tPrediction  \n",
    ".14\tStop  \n",
    ".29\tBicycles crossing  \n",
    ".38\tKeep right  \n",
    ".25\tRoad work  \n",
    ".22\tBumpy Road  \n",
    "\n",
    "For the third image, the model is not sure that this is a children crossing (probability of 0.31). The top five soft max probabilities were\n",
    "\n",
    "Probability\tPrediction  \n",
    ".28\tChildren crossing  \n",
    ".01\tSpeed limit (30km/h)  \n",
    ".03\tSpeed limit (60km/h)  \n",
    ".00\tSpeed limit (20km/h)  \n",
    ".06\tEnd of speed limit (80km/h)  \n",
    "\n",
    "For the fourth image, the model is relatively sure that this is a no entry (probability of 1.0), and the image does contain a no entry sign. The top five soft max probabilities were\n",
    "\n",
    "Probability\tPrediction  \n",
    ".17\tNo entry  \n",
    ".14\tStop  \n",
    ".09\tNo passing  \n",
    ".16\tVehicles over 3.5 metric tons prohibited  \n",
    ".12\tPriority road    \n",
    "\n",
    "For the fifth image, the model is relatively sure that this is a no entry (probability of 1.0), and the image does contain a no entry sign. The top five soft max probabilities were\n",
    "\n",
    "Probability\tPrediction  \n",
    ".17\tNo entry  \n",
    ".14\tStop  \n",
    ".09\tNo passing  \n",
    ".16\tVehicles over 3.5 metric tons prohibited  \n",
    ".41\tEnd of no passing  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
